{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pipeline for poswise frequency analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aporshnev/python_pipelines/blob/main/pipeline_for_poswise_frequency_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7xUh9cVHBWC"
      },
      "source": [
        "Пайплайн, в начале которого происходит автоматическое определение языка, на котором написан переданный текст, далее текст токенизируется, лемматизируется, происходит первичный морфологический анализ и даже определяется, является ли это слово знаменательным. Полученные такой обработкой данные автоматически сортируются и отбираются в зависимости от запрашиваемых частеречных тэгов. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU5hjDg3IgYR"
      },
      "source": [
        "0. Скачиваем и импортируем библиотеку для определения языка, библиотеку для нлп, пандас для удобного формата данных и функцию reduce для написания красивого кода."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12JLnJkiAPeW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ea3488-7b4d-445e-9e13-007c49815a5e"
      },
      "source": [
        "pip install langdetect -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 686 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 696 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 716 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 727 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 747 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 757 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 768 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 778 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 788 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 798 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 808 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 819 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 829 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 839 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 849 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 860 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 870 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 880 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 890 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 901 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 911 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 921 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 931 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 942 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 952 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 962 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 972 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 981 kB 5.4 MB/s \n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOYcTyABCmdH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54023a8-0518-4469-c737-d44e43df6171"
      },
      "source": [
        "pip install spacy==3.0.0 -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 12.7 MB 224 kB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 456 kB 55.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 623 kB 49.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiEu5qyUCOQ-",
        "outputId": "12eb4b72-034f-48b1-febb-c00a88560cd7"
      },
      "source": [
        "! python -m spacy download ru_core_news_sm -q\n",
        "! python -m spacy download en_core_web_sm -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 17.9 MB 138 kB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 8.2 MB/s \n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n",
            "\u001b[K     |████████████████████████████████| 13.7 MB 69 kB/s \n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76j89nCJKeNH"
      },
      "source": [
        "from functools import reduce\n",
        "\n",
        "import pandas as pd\n",
        "from langdetect import detect\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUMWRfxwIxPO"
      },
      "source": [
        "1. Собственно, вот сами составляющие пайплайна. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1SK0VkiMI6V"
      },
      "source": [
        "def aggregate_info(text):\n",
        "    '''\n",
        "    Creates a df containing info about token, lemma, pos,\n",
        "    and whether this word is a stopword\n",
        "    '''\n",
        "    # detect language ad find appropriate model\n",
        "    lang = detect(text)\n",
        "    if lang == 'en':\n",
        "        model = 'en_core_web_sm'\n",
        "    elif lang == 'ru':\n",
        "        model = 'ru_core_news_sm'\n",
        "    nlp = spacy.load(model)\n",
        "\n",
        "\n",
        "    def compose_dict(d, token):\n",
        "        '''\n",
        "        Fills dict with features of new tokens\n",
        "        '''\n",
        "        d['token'].append(token.text)\n",
        "        d['lemma'].append(token.lemma_)\n",
        "        d['pos'].append(token.pos_)\n",
        "        d['stop'].append(token.is_stop)\n",
        "        return d\n",
        "\n",
        "    d = {\n",
        "        'token' : [],\n",
        "        'lemma' : [],\n",
        "        'pos': [],\n",
        "        'stop': []\n",
        "    }\n",
        "    \n",
        "    # decapitalize all the words\n",
        "    text = ' '.join(map(lambda x: x.lower(), text.split()))\n",
        "\n",
        "\n",
        "    return pd.DataFrame(reduce(compose_dict, nlp(text), d))\n",
        "\n",
        "def form_freq_df(word_freq: pd.DataFrame) -> pd.DataFrame:\n",
        "    '''\n",
        "    Forms df in which a row is a unique token \n",
        "    for which the number of occurences is specified\n",
        "    '''\n",
        "    word_freq = pd.DataFrame(aggregate_info(text).value_counts()).reset_index()\n",
        "    word_freq.columns = ['token', 'lemma', 'pos', 'stop', 'count']\n",
        "    return word_freq\n",
        "\n",
        "\n",
        "def get_top_freq_words(data: pd.DataFrame, pos: str) -> pd.DataFrame:\n",
        "    '''\n",
        "    sorts a df by pos and number of occurences\n",
        "    '''\n",
        "    return data[data.pos == pos].sort_values(by='count', ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOyY6JJRKAZt"
      },
      "source": [
        "1.1 Предлагаю работать с началом первой главы \"Гарри Поттер и принц полукровка\"\n",
        "Кладем текст в переменную text и начинаем удивительное путешествие"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GPgZ2wHOCEh"
      },
      "source": [
        "text = '''It was nearing midnight and the Prime Minister was sitting alone in his office, reading a long\n",
        "memo that was slipping through his brain without leaving the slightest trace of meaning behind. He\n",
        "was waiting for a call from the President of a far distant country, and between wondering when the\n",
        "wretched man would telephone, and trying to suppress unpleasant memories of what had been a\n",
        "very long, tiring, and difficult week, there was not much space in his head for anything else. The\n",
        "more he attempted to focus on the print on the page before him, the more clearly the Prime\n",
        "Minister could see the gloating face of one of his political opponents. This particular opponent had\n",
        "appeared on the news that very day, not only to enumerate all the terrible things that had happened\n",
        "in the last week (as though anyone needed reminding) but also to explain why each and every one of\n",
        "them was the government’s fault.\n",
        "The Prime Minister’s pulse quickened at the very thought of these accusations, for they were\n",
        "neither fair nor true. How on earth was his government supposed to have stopped that bridge\n",
        "collapsing? It was outrageous for anybody to suggest that they were not spending enough on bridges.\n",
        "The bridge was fewer than ten years old, and the best experts were at a loss to explain why it had\n",
        "snapped cleanly in two, sending a dozen cars into the watery depths of the river below. And how\n",
        "dare anyone suggest that it was lack of policemen that had resulted in those two very nasty and wellpublicized murders? Or that the government should have somehow foreseen the freak hurricane in\n",
        "the West Country that had caused so much damage to both people and property? And was it his\n",
        "fault that one of his Junior Ministers, Herbert Chorley, had chosen this week to act so peculiarly that\n",
        "he was now going to be spending a lot more time with his family? \n",
        "“A grim mood has gripped the country,” the opponent had concluded, barely concealing his own\n",
        "broad grin.\n",
        "And unfortunately, this was perfectly true. The Prime Minister felt it himself; people really did\n",
        "seem more miserable than usual. Even the weather was dismal; all this chilly mist in the middle of\n",
        "July…It wasn’t right, it wasn’t normal… '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amXl-Pi_KT5Z"
      },
      "source": [
        "Собираем общий анализ слов в тексте, выглядит это так"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RpjoHHR69z8m",
        "outputId": "dd42b371-9288-44fc-9941-4b008881ca53"
      },
      "source": [
        "analysis = aggregate_info(text)\n",
        "analysis.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>stop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>it</td>\n",
              "      <td>it</td>\n",
              "      <td>PRON</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>was</td>\n",
              "      <td>be</td>\n",
              "      <td>AUX</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nearing</td>\n",
              "      <td>near</td>\n",
              "      <td>VERB</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>midnight</td>\n",
              "      <td>midnight</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      token     lemma    pos   stop\n",
              "0        it        it   PRON   True\n",
              "1       was        be    AUX   True\n",
              "2   nearing      near   VERB  False\n",
              "3  midnight  midnight   NOUN  False\n",
              "4       and       and  CCONJ   True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGxlGhx5KZfg"
      },
      "source": [
        "Формируем из этого частотный словарь, выглядит так"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XALL0-2N97mu",
        "outputId": "bb5b2ef1-c64b-4ead-eb7a-7bdcbf812e26"
      },
      "source": [
        "word_freq = form_freq_df(analysis)\n",
        "word_freq.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>stop</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>DET</td>\n",
              "      <td>True</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>False</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>was</td>\n",
              "      <td>be</td>\n",
              "      <td>AUX</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>ADP</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  token lemma    pos   stop  count\n",
              "0   the   the    DET   True     28\n",
              "1     ,     ,  PUNCT  False     17\n",
              "2   was    be    AUX   True     15\n",
              "3    of    of    ADP   True     11\n",
              "4   and   and  CCONJ   True     11"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJdFK1rdKg3f"
      },
      "source": [
        "И при помощи такой удобной функции можно выбирать, слова какой части речи мы хотим искать "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "O7B1Z3BB-JWV",
        "outputId": "b6bbbd77-27a2-45ca-bffa-b89669764e23"
      },
      "source": [
        "top = get_top_freq_words(word_freq, 'NOUN')\n",
        "top.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>stop</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>minister</td>\n",
              "      <td>minister</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>week</td>\n",
              "      <td>week</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>country</td>\n",
              "      <td>country</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>government</td>\n",
              "      <td>government</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>opponent</td>\n",
              "      <td>opponent</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         token       lemma   pos   stop  count\n",
              "18    minister    minister  NOUN  False      4\n",
              "24        week        week  NOUN  False      3\n",
              "26     country     country  NOUN  False      3\n",
              "23  government  government  NOUN  False      3\n",
              "32    opponent    opponent  NOUN  False      2"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-LcIg6rKl6c"
      },
      "source": [
        "Вот такие у нас топ10 глаголов, наречий и прилагательных "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqKslIbV-VqZ",
        "outputId": "5b22248f-e54d-44c7-8d19-ce546ecc0305"
      },
      "source": [
        "print(get_top_freq_words(word_freq, 'VERB').head(10)['token'].to_list())\n",
        "print(get_top_freq_words(word_freq, 'ADV').head(10)['token'].to_list())\n",
        "print(get_top_freq_words(word_freq, 'ADJ').head(10)['token'].to_list())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['suggest', 'were', 'spending', 'explain', 'wellpublicized', 'stopped', 'snapped', 'slipping', 'sitting', 'sending']\n",
            "['more', 'how', 'very', 'why', 'so', 'enough', 'peculiarly', 'perfectly', 'really', 'now']\n",
            "['prime', 'much', 'true', 'very', 'long', 'more', 'watery', 'usual', 'unpleasant', 'normal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2xDv-ciKqLq"
      },
      "source": [
        "1.2 Теперь то же, но для русского. Текст берем тот же самый, но в профессиональном переводе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM8BbzpE-X9V"
      },
      "source": [
        "text = '''Приближалась полночь. Премьер-министр си­дел у себя в кабинете в полном одиночестве и читал длинный меморандум. Строчки мелькали перед гла­зами, не задевая сознания. Премьер-министр ожи­дал звонка от президента одной далекой страны. Он раздумывал, когда же наконец позвонит этот зло­счастный тип, и одновременно пытался отделаться от неприятных воспоминаний о необычайно дол­гой и утомительной неделе; ни на что другое в го­лове у него просто не оставалось места. Чем больше он старался сосредоточиться на печатной страни­це, которая лежала перед ним на столе, тем отчет­ливее видел перед собой злорадное лицо одного из своих политических противников. Не далее как се­годня противник этот, выступая в программе но­востей, не только перечислил все ужасные проис­шествия минувшей недели (как будто кому-то тре­бовалось об этом напоминать), но еще и подробно объяснил, почему в каждом из них виновато пра­вительство. У премьер-министра зачастил пульс от одной мыс­ли об этих подлых и несправедливых обвинениях. Интересно, каким это образом правительство мог­ло помешать мосту обрушиться? Возмутительная нелепость — намекать, будто на строительство мос­тов тратится недостаточно средств. Мосту не было еще и десяти лет, лучшие эксперты теряются в до­гадках, отчего он вдруг разломился ровно посере­дине, отправив дюжину автомобилей на дно реки. И как только наглости хватило заявить, что причи­на двух зверских убийств, широко освещавшихся в средствах массовой информации, — нехватка по­лицейских? И что правительство обязано было ка­ким-то образом предвидеть внезапный ураган, про­несшийся по нескольким графствам к юго-западу от Лондона, причинивший огромный ущерб и сопро­вождавшийся человеческими жертвами? И разве он, премьер-министр, виноват в том, что один из его заместителей, Герберт Чорли, именно на этой не­деле начал вести себя так своеобразно, что ему те­перь придется значительно больше времени про­водить дома, с семьей? «Страну охватило уныние», — закончил свою речь представитель оппозиции, почти не скрывая широ­кой довольной улыбки. Увы, тут он сказал чистую правду. Премьер-ми­нистр и сам это почувствовал: люди выглядели не­привычно подавленными. Даже погода стояла без­радостная. Промозглый туман в середине июля... Не­правильно это. Ненормально.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1OgB-Q7R_8Lo",
        "outputId": "ab695eab-b405-4428-c240-ca3afc1cc122"
      },
      "source": [
        "analysis = aggregate_info(text)\n",
        "analysis.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>stop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>приближалась</td>\n",
              "      <td>приближаться</td>\n",
              "      <td>VERB</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>полночь</td>\n",
              "      <td>полночь</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>премьер</td>\n",
              "      <td>премьер</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          token         lemma    pos   stop\n",
              "0  приближалась  приближаться   VERB  False\n",
              "1       полночь       полночь   NOUN  False\n",
              "2             .             .  PUNCT  False\n",
              "3       премьер       премьер   NOUN  False\n",
              "4             -             -   NOUN  False"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cCRpRTiJDbQS",
        "outputId": "9479f4b4-6840-47e1-d61d-b6769c40dc32"
      },
      "source": [
        "word_freq = form_freq_df(analysis)\n",
        "word_freq.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>stop</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>False</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>False</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>в</td>\n",
              "      <td>в</td>\n",
              "      <td>ADP</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>и</td>\n",
              "      <td>и</td>\n",
              "      <td>CCONJ</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>на</td>\n",
              "      <td>на</td>\n",
              "      <td>ADP</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  token lemma    pos   stop  count\n",
              "0     ,     ,  PUNCT  False     29\n",
              "1     .     .  PUNCT  False     16\n",
              "2     в     в    ADP   True      9\n",
              "3     и     и  CCONJ   True      9\n",
              "4    на    на    ADP   True      6"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jnZVkfpVGWww",
        "outputId": "d8c63f68-ecd4-415e-bfaa-72498e3cac84"
      },
      "source": [
        "top = get_top_freq_words(word_freq, 'NOUN')\n",
        "top.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>lemma</th>\n",
              "      <th>pos</th>\n",
              "      <th>stop</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>премьер</td>\n",
              "      <td>премьер</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>министр</td>\n",
              "      <td>министр</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>правительство</td>\n",
              "      <td>правительство</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>образом</td>\n",
              "      <td>образ</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>False</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            token          lemma   pos   stop  count\n",
              "5               -              -  NOUN  False      6\n",
              "7         премьер        премьер  NOUN  False      5\n",
              "13        министр        министр  NOUN  False      3\n",
              "18  правительство  правительство  NOUN  False      2\n",
              "27        образом          образ  NOUN  False      2"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRkS66uzK0dR"
      },
      "source": [
        "Как можно заметить, топ слов по каждой из проверенных частей речи примерно совпадает что в русском, что в английском. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7QH2NOfGbI6",
        "outputId": "0b53487c-1047-4404-b631-27084f473ad9"
      },
      "source": [
        "print(get_top_freq_words(word_freq, 'VERB').head(10)['token'].to_list())\n",
        "print(get_top_freq_words(word_freq, 'ADV').head(10)['token'].to_list())\n",
        "print(get_top_freq_words(word_freq, 'ADJ').head(10)['token'].to_list())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['лежала', 'обязано', 'тратится', 'разломился', 'перечислил', 'охватило', 'отправив', 'отделаться', 'оставалось', 'освещавшихся']\n",
            "['еще', 'когда', 'почти', 'одновременно', 'отчего', 'отчет\\xadливее', 'подробно', 'тут', 'увы', 'широко']\n",
            "['ненормально', 'ужасные', 'далекой', 'своеобразно', 'сам', 'чистую', 'человеческими', 'утомительной', 'подавленными', 'лучшие']\n"
          ]
        }
      ]
    }
  ]
}